<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-08-22T16:39:10-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Bobby Marsland: Theoretical Biophysicist</title><subtitle>Postdoctoral Fellow in the Theoretical Biophysics Group at Boston University</subtitle><author><name>Bobby Marsland</name></author><entry><title type="html">Collective computation in biological populations</title><link href="http://localhost:4000/research/collective-computation" rel="alternate" type="text/html" title="Collective computation in biological populations" /><published>2019-08-20T20:00:07-04:00</published><updated>2019-08-20T20:00:07-04:00</updated><id>http://localhost:4000/research/collective-computation</id><content type="html" xml:base="http://localhost:4000/research/collective-computation">&lt;p&gt;Ecosystems may seem an unlikely substrate for sophisticated computation. But two key features make them a promising way for solving sophisticated machine learning problems based on constrained optimization. First of all, self-replication provides stable constraint enforcement. Stable coexistence requires that the environmental state satisfy a precise set of conditions, such that the population growth rates of all species are simultaneously zero. A slight deviation from this constraint will lead to exponential growth or decay of one or more population sizes, which in turn will modify the environment until these conditions are restored. Secondly, distributing the computation over a whole ecosystem provides automatic parallelization, which becomes particularly important for solving problems efficiently in high dimension.&lt;/p&gt;

&lt;p&gt;This intuition can be transformed into a precise mathematical duality, as my coauthors and I have shown here. The duality opens some interesting horizons for thinking about ecosystems and about classic machine learning problems, suggesting new observables for field ecologists and new algorithms for online learning.&lt;/p&gt;

&lt;p&gt;But is it possible to actually use an ecosystem to perform a computation? The adaptive immune system is a natural place to start. T cells are clearly performing a collective computation to determine whether a given antigen comes from a native protein or from a pathogen. I am currently investigating the possibility that the immune system is implementing a standard algorithm for outlier detection called a single-class support vector machine (SVM). My colleagues and I are using published proteomes of mammals and pathogens to determine whether my proposal is feasible under biologically realistic conditions.&lt;/p&gt;

&lt;p&gt;Natural ecosystems are unnecessarily complex and cumbersome, however, for implementing pre-defined computations. For this purpose, it is much more convenient to employ bare DNA, which can be efficiently replicated via the polymerase chain reaction (PCR), and has already been employed to implement sophisticated machine learning algorithms. I am currently developing a proposal for a general-purpose single-class SVM based on PCR and strand displacement reactions.&lt;/p&gt;</content><author><name>Bobby Marsland</name></author><summary type="html">Ecosystems may seem an unlikely substrate for sophisticated computation. But two key features make them a promising way for solving sophisticated machine learning problems based on constrained optimization. First of all, self-replication provides stable constraint enforcement. Stable coexistence requires that the environmental state satisfy a precise set of conditions, such that the population growth rates of all species are simultaneously zero. A slight deviation from this constraint will lead to exponential growth or decay of one or more population sizes, which in turn will modify the environment until these conditions are restored. Secondly, distributing the computation over a whole ecosystem provides automatic parallelization, which becomes particularly important for solving problems efficiently in high dimension.</summary></entry><entry><title type="html">Typicality in microbial ecology</title><link href="http://localhost:4000/research/typical-ecology" rel="alternate" type="text/html" title="Typicality in microbial ecology" /><published>2019-08-20T20:00:06-04:00</published><updated>2019-08-20T20:00:06-04:00</updated><id>http://localhost:4000/research/typical-ecology</id><content type="html" xml:base="http://localhost:4000/research/typical-ecology">&lt;p&gt;Microbial ecosystems manifest one of the main technical obstacles to predictive modeling of biological systems, which arises from their extreme heterogeneity. The standard methods of statistical mechanics produce powerful and robust predictions about the behavior of large collections of functionally identical particles, which are easily extended to mixtures of a few different kinds of components. But in most biological systems, the number of distinct types of components is unmanageably large, whether we are considering the 20,000 different genes in the human genome, or the ???? kinds of proteins in the proteome, or the 5,000 distinct metabolites in the metabolome. Microbial ecosystems reproduce this same difficulty on a bigger scale, with hundreds to thousands of coexisting “species” in a given natural community. The development of inexpensive DNA sequencing has made these systems an attractive setting for developing and testing new theoretical methods for overcoming this hurdle. Highly diverse microbial communities can be readily found on any plant leaf, pond droplet, or grain of soil, and sequencing technology lets us determine which species are present there and in what abundance.&lt;/p&gt;

&lt;p&gt;My colleagues and I have been adapting methods from the physics of disordered materials to this new setting, deriving predictions about the diversity, composition and sensitivity of heterogeneous communities based on summary statistics about consumption preferences and byproduct secretion in the regional species pool. The key assumption behind these methods is that the parameters characterizing each species can be modeled as independent random variables drawn from a given probability distribution. This seems like an extreme assumption, given how much specific structure is already known about microbial behavior. But we have shown that at sufficiently high levels of diversity, the strong interactions between specific pairs of organisms based on known mechanisms can be overwhelmed by the sheer number of weak, uncharacterized interactions with all the other species in the system. When this happens, the community structure shifts to a “typical” state, whose community-level properties depend only on the summary statistics characterizing the regional pool.&lt;/p&gt;

&lt;p&gt;To check our calculations and facilitate hypothesis generation, I have also been developing a Python package for rapidly simulating diverse microbial ecosystems with randomly sampled parameters. Using this package, I have shown that the robust patterns observed in large-scale surveys of microbial diversity (such as the Human Microbiome Project and Earth Microbiome Project) reflect the “typical” structure of diverse communities.&lt;/p&gt;

&lt;p&gt;I have also used this software to study some novel ecological phenomena that can arise in self-sufficient microbial ecosystems. Since microbes generically produce usable byproducts whenever they consume an energy source, they can autonomously generate a complex chemical environment that supports a diverse community even when only a single energy source is supplied externally. This differs from the standard case considered in macroscopic ecology, where environmental conditions are either fixed or modified only through consumption. By performing simulations of this extreme case of a fully self-generated environment, I identified a transition in community structure as a function of the supply rate of the externally provided resource. At high supply rates, the community-level metabolic network percolates, and all possible byproducts are produced at sufficiently high concentrations to significantly contribute to the growth of some set of species. The scaling of diversity with the number of supplied resources in this regime agrees with analytic predictions obtained for “typical” communities. But at low supply rates, only species that directly consume the externally supplied resource can survive, and the resulting low-diversity state no longer satisfies the assumptions for calculating “typical” community properties.&lt;/p&gt;</content><author><name>Bobby Marsland</name></author><summary type="html">Microbial ecosystems manifest one of the main technical obstacles to predictive modeling of biological systems, which arises from their extreme heterogeneity. The standard methods of statistical mechanics produce powerful and robust predictions about the behavior of large collections of functionally identical particles, which are easily extended to mixtures of a few different kinds of components. But in most biological systems, the number of distinct types of components is unmanageably large, whether we are considering the 20,000 different genes in the human genome, or the ???? kinds of proteins in the proteome, or the 5,000 distinct metabolites in the metabolome. Microbial ecosystems reproduce this same difficulty on a bigger scale, with hundreds to thousands of coexisting “species” in a given natural community. The development of inexpensive DNA sequencing has made these systems an attractive setting for developing and testing new theoretical methods for overcoming this hurdle. Highly diverse microbial communities can be readily found on any plant leaf, pond droplet, or grain of soil, and sequencing technology lets us determine which species are present there and in what abundance.</summary></entry><entry><title type="html">Relevant variables in microbial communities</title><link href="http://localhost:4000/research/microbiome-observables" rel="alternate" type="text/html" title="Relevant variables in microbial communities" /><published>2019-08-20T20:00:05-04:00</published><updated>2019-08-20T20:00:05-04:00</updated><id>http://localhost:4000/research/microbiome-observables</id><content type="html" xml:base="http://localhost:4000/research/microbiome-observables">&lt;p&gt;The concept of a “species” is notoriously ill-defined in the microbial realm. Instead of the sharp distinctions between different kinds of plants and animals we find in the macroscopic world, microbes manifest a fuzzier continuum of phenotypes. Given this blurriness, it should come as no surprise that it is difficult to predict “species”-level composition of microbial communities. But natural microbial communities do have sufficiently stable functional properties to be effectively utilized by macroscopic organisms to accomplish definite tasks. This means that there should be some community-level quantities that are reproducible and controllable, and some “relevant variables” that reliably control them, but what these quantities could be remains an open question.&lt;/p&gt;

&lt;p&gt;I am currently following up on an observation by some of my colleagues that the composition of communities grown on single carbon sources is reproducible at a sufficiently high taxonomic level. Specifically, the family-level structure of the communities is sensitive to the choice of carbon source, but is strongly conserved for different communities, sampled from different field sites, when grown on the same carbon source. My first goal is to identify the chemical features of the carbon source that determine the community structure, using standard machine learning algorithms to predict community composition on novel carbon sources based on chemical similarity, and comparing these predictions with the measurements performed by my collaborators.&lt;/p&gt;

&lt;p&gt;The next step is to develop a method for inferring reproducible observables directly from the data, instead of using the historically contingent family groupings. An interesting theoretical procedure for this was proposed some time ago, using the eigenvectors of an individual-level, environment-specific interaction matrix. It is currently impossible to measure the entries of this matrix, however, and so practical implementation of this program requires a controlled procedure for estimating the matrix directly from the data. I am currently developing such a procedure, applying it to my collaborators’ data, and exploring other ways of obtaining meaningful functional groupings from the inferred matrix.&lt;/p&gt;</content><author><name>Bobby Marsland</name></author><summary type="html">The concept of a “species” is notoriously ill-defined in the microbial realm. Instead of the sharp distinctions between different kinds of plants and animals we find in the macroscopic world, microbes manifest a fuzzier continuum of phenotypes. Given this blurriness, it should come as no surprise that it is difficult to predict “species”-level composition of microbial communities. But natural microbial communities do have sufficiently stable functional properties to be effectively utilized by macroscopic organisms to accomplish definite tasks. This means that there should be some community-level quantities that are reproducible and controllable, and some “relevant variables” that reliably control them, but what these quantities could be remains an open question.</summary></entry><entry><title type="html">Thermodynamic constraints in living matter</title><link href="http://localhost:4000/research/thermodynamic-constraints" rel="alternate" type="text/html" title="Thermodynamic constraints in living matter" /><published>2019-08-20T20:00:04-04:00</published><updated>2019-08-20T20:00:04-04:00</updated><id>http://localhost:4000/research/thermodynamic-constraints</id><content type="html" xml:base="http://localhost:4000/research/thermodynamic-constraints">&lt;p&gt;&lt;a href=&quot;https://en.wikiquote.org/wiki/Arthur_Eddington&quot;&gt;Sir Arthur Eddington&lt;/a&gt; famously remarked that the Second Law of Thermodynamics holds “the supreme position among the laws of Nature.” Half a century earlier, Ludwig Boltzmann had already noted that thermodynamics constrains the activity of living systems, in such a way that the Darwinian “struggle for existence” could be framed in terms of entropy. Recent progress in non-equilibrium statistical mechanics has opened up new possibilities for fleshing out these insights, determining which features of biological activity are constrained by thermodynamic laws, and what the “negative entropy” obtained in the “struggle for existence” is used for.&lt;/p&gt;

&lt;p&gt;One striking property of living materials is their combination of mechanical strength and rapid adaptability. This combination is essential for effective locomotion and for autonomous damage repair, and is rarely found in inanimate systems. I have found a way of precisely characterizing this qualitative observation in terms of thermodynamic constraints, showing how the internal chemical potential differences maintained by cellular metabolism can give biological materials their special characteristics.&lt;/p&gt;

&lt;p&gt;Thermodynamic consistency also places general constraints on the temporal precision of physical processes at finite temperature. One might expect that these constraints would affect the design of biochemical “clocks,” such as the KaiABC system that sets the circadian rhythm in a large class of photosynthetic bacteria. I ran simulations of the KaiABC system and used published data from experiments and other biochemical clock models to determine how close they came to the thermodynamic limit. I found that the precision of these biochemical processes was always at least an order of magnitude worse than the theoretical optimum, indicating that evolution somehow failed to fully optimize this figure of merit. Using a simplified toy model capturing the essential structure of the KaiABC system, I showed that the optimum could be achieved using a molecule with a sufficiently large number of sequentially accessed internal states, with comparable reaction rates for each internal step. This suggests that the sub-optimality of the clock precision is at least partially due to the difficulty of implementing such a large chemical cycle on a single molecule.&lt;/p&gt;

&lt;p&gt;Alongside these specific projects, I have also authored or contributed to several general treatments of various aspects of non-equilibrium statistical mechanics, including a review article providing an accessible introduction to some of the most important recent developments in the field.&lt;/p&gt;</content><author><name>Bobby Marsland</name></author><summary type="html">Sir Arthur Eddington famously remarked that the Second Law of Thermodynamics holds “the supreme position among the laws of Nature.” Half a century earlier, Ludwig Boltzmann had already noted that thermodynamics constrains the activity of living systems, in such a way that the Darwinian “struggle for existence” could be framed in terms of entropy. Recent progress in non-equilibrium statistical mechanics has opened up new possibilities for fleshing out these insights, determining which features of biological activity are constrained by thermodynamic laws, and what the “negative entropy” obtained in the “struggle for existence” is used for.</summary></entry><entry><title type="html">Conditions for emergence of self-sustaining metabolic networks</title><link href="http://localhost:4000/research/emergence-metabolism" rel="alternate" type="text/html" title="Conditions for emergence of self-sustaining metabolic networks" /><published>2019-08-20T20:00:03-04:00</published><updated>2019-08-20T20:00:03-04:00</updated><id>http://localhost:4000/research/emergence-of-metabolism</id><content type="html" xml:base="http://localhost:4000/research/emergence-metabolism">&lt;p&gt;One of the distinctive features of living matter is the presence of self-sustaining metabolic reaction networks. Every time a cell divides, it must take in chemical compounds available in its environment, and use them to double the quantity of each internal molecular species. General properties of such collectively autocatalytic reaction networks have been studied for many decades, but the rise of biosphere-scale databases of biochemical reactions has created new avenues for working out the necessary conditions for the spontaneous emergence of such networks.&lt;/p&gt;

&lt;p&gt;My coauthors and I have shown how large and complex reaction networks could have spontaneously arisen in a variety of proposed pre-biotic geochemical scenarios, before the emergence of nitrogen-fixing or phosphate-fixing enzymes &lt;a href=&quot;#goldford2018boundary&quot;&gt;(Goldford, Hartman, Marsland, &amp;amp; Segre, Preprints)&lt;/a&gt;. I have been investigating the properties of collectively autocatalytic sub-networks in some of these scenarios, and plan to use methods from the physics of disordered systems to study the similarities and differences between these real sub-networks and the autocatalytic portions of random networks.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;goldford2018boundary&quot;&gt;Goldford, J. E., Hartman, H., Marsland, R., &amp;amp; Segre, D. (Preprints). Boundary conditions for early life converge to an organo-sulfur metabolism. &lt;i&gt;BioRxiv&lt;/i&gt;, 487660.&lt;/span&gt;
    

    
    &lt;a href=&quot;https://www.biorxiv.org/content/10.1101/487660v1.abstract&quot;&gt;&lt;button class=&quot;btn btnId btnPub--BibTex&quot; id=&quot;b_goldford2018boundary-url&quot; style=&quot;outline:none;&quot;&gt;arXiv&lt;/button&gt;&lt;/a&gt;
    
    
    
    
    

    &lt;/li&gt;&lt;/ol&gt;</content><author><name>Bobby Marsland</name></author><summary type="html">One of the distinctive features of living matter is the presence of self-sustaining metabolic reaction networks. Every time a cell divides, it must take in chemical compounds available in its environment, and use them to double the quantity of each internal molecular species. General properties of such collectively autocatalytic reaction networks have been studied for many decades, but the rise of biosphere-scale databases of biochemical reactions has created new avenues for working out the necessary conditions for the spontaneous emergence of such networks.</summary></entry><entry><title type="html">Directed differentiation with Linear Algebra Projections</title><link href="http://localhost:4000/research/cell-types" rel="alternate" type="text/html" title="Directed differentiation with Linear Algebra Projections" /><published>2019-08-20T20:00:02-04:00</published><updated>2019-08-20T20:00:02-04:00</updated><id>http://localhost:4000/research/cell-types</id><content type="html" xml:base="http://localhost:4000/research/cell-types">&lt;p&gt;Induced pluripotent stem cells (iPSC’s) have generated considerable excitement for the future of regenerative medicine. Since these cells can be generated directly from readily accessible somatic patient cells, they can be used to grow new tissues and eventually organs with no risk of immune rejection. Coaxing the cells to differentiate into the desired tissue remains a major challenge, and the development of effective protocols is hampered by the fact that the success or failure of a given attempt is difficult to determine until the cells are delivered to a host.&lt;/p&gt;

&lt;p&gt;Information about the cell type is already encoded in the gene expression levels as soon as the protocol is complete, however, and my colleagues have developed a reliable method for extracting this, based on the linear algebra of non-orthogonal projections. I am currently working with a group at the BU Center for Regenerative Medicine, using this method to help develop protocols for generating lung cells.&lt;/p&gt;</content><author><name>Bobby Marsland</name></author><summary type="html">Induced pluripotent stem cells (iPSC’s) have generated considerable excitement for the future of regenerative medicine. Since these cells can be generated directly from readily accessible somatic patient cells, they can be used to grow new tissues and eventually organs with no risk of immune rejection. Coaxing the cells to differentiate into the desired tissue remains a major challenge, and the development of effective protocols is hampered by the fact that the success or failure of a given attempt is difficult to determine until the cells are delivered to a host.</summary></entry><entry><title type="html">Bayesian analysis for small molecule sensors</title><link href="http://localhost:4000/research/bayesian-microscopy" rel="alternate" type="text/html" title="Bayesian analysis for small molecule sensors" /><published>2019-08-20T20:00:01-04:00</published><updated>2019-08-20T20:00:01-04:00</updated><id>http://localhost:4000/research/bayesian-microscopy</id><content type="html" xml:base="http://localhost:4000/research/bayesian-microscopy">&lt;p&gt;The combination of gene editing and lattice light-sheet microscopy has opened a new era in cell biology. It is now possible, in principle, to fluorescently label any biologically relevant molecule and measure its dynamics across the whole cell in real time. Not only can proteins be labeled, by directly appending the code for a fluorescent domain to the gene of interest, but so can small molecules and ions, by hijacking the naturally occurring proteins that transduce information about their concentrations, using them to create artificial fluorescent probes. Stitching these sensors to other protein domains that specifically bind to different parts of the cell can provide additional spatial resolution, detecting even a small number of copies of the molecule of interest in the vicinity of a certain target structure. A number of small molecules such as cyclic AMP and phosophotidylinositol (PI) play crucial roles in signal transduction, and a complete understanding how the signal is processed requires careful measurements of their spatiotemporal dynamics in response to specific stimuli.&lt;/p&gt;

&lt;p&gt;Inferring the dynamics of the molecules of interest from the observed behavior of the fluorescent probes, however, presents new challenges. The timescale of concentration changes in the molecule of interest can easily be comparable to the timescale for the probe to bind to its target, requiring a detailed kinetic model to back out the desired information. While it is usually straightforward to write down the kinetics for a well-characterized probe, the multi-domain molecules developed for the latest high-resolution measurements require a large number of unknown kinetic parameters, whose in vitro values do not necessarily reflect their behavior in the cytoplasm. Using these high-dimensional models correctly requires great care, because they easily give rise to “sloppy” directions in parameter space, which are unconstrained by the available data. I have developed some expertise in using Bayesian analysis to guide careful interpretation of the results of this kind of experiment, in the context of detecting phosphorylated PI molecules recruited to sites of clathrin-mediated endocytosis.&lt;/p&gt;</content><author><name>Bobby Marsland</name></author><summary type="html">The combination of gene editing and lattice light-sheet microscopy has opened a new era in cell biology. It is now possible, in principle, to fluorescently label any biologically relevant molecule and measure its dynamics across the whole cell in real time. Not only can proteins be labeled, by directly appending the code for a fluorescent domain to the gene of interest, but so can small molecules and ions, by hijacking the naturally occurring proteins that transduce information about their concentrations, using them to create artificial fluorescent probes. Stitching these sensors to other protein domains that specifically bind to different parts of the cell can provide additional spatial resolution, detecting even a small number of copies of the molecule of interest in the vicinity of a certain target structure. A number of small molecules such as cyclic AMP and phosophotidylinositol (PI) play crucial roles in signal transduction, and a complete understanding how the signal is processed requires careful measurements of their spatiotemporal dynamics in response to specific stimuli.</summary></entry></feed>